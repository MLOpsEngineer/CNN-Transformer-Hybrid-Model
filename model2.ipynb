{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n",
      "/Users/petersong/Library/Caches/pypoetry/virtualenvs/cnn-transformer-hybrid-model-fa1p7jlT-py3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "에포크 1/5:   8%|▊         | 30/391 [00:43<08:22,  1.39s/it, loss=0.0267]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm  # 학습 진행 상황을 보여주기 위한 라이브러리\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4  # 학습 안정성을 위해 학습률을 낮춤\n",
    "MAX_VOCAB_SIZE = 20000  # 어휘 사전 크기 증가\n",
    "MAX_SEQ_LEN = 512  # 시퀀스 길이 조정\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 사용)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 데이터 준비\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for label, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# 어휘 사전 구축\n",
    "train_iter, test_iter = IMDB()\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), max_tokens=MAX_VOCAB_SIZE, specials=[\"<pad>\", \"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 데이터셋을 다시 로드하여 사용 (중요)\n",
    "train_iter, test_iter = IMDB()\n",
    "\n",
    "def text_pipeline(text):\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab[token] for token in tokens]\n",
    "    # 시퀀스 길이 조정\n",
    "    if len(token_ids) > MAX_SEQ_LEN:\n",
    "        token_ids = token_ids[:MAX_SEQ_LEN]\n",
    "    else:\n",
    "        token_ids += [vocab[\"<pad>\"]] * (MAX_SEQ_LEN - len(token_ids))\n",
    "    return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "def label_pipeline(label):\n",
    "    return torch.tensor(1 if label == 'pos' else 0, dtype=torch.long)\n",
    "\n",
    "# 데이터셋 생성\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_iter):\n",
    "        self.data = []\n",
    "        for label, text in data_iter:\n",
    "            try:\n",
    "                text_tensor = text_pipeline(text)\n",
    "                label_tensor = label_pipeline(label)\n",
    "                self.data.append((text_tensor, label_tensor))\n",
    "            except Exception as e:\n",
    "                # 데이터 처리 중 발생하는 오류 처리\n",
    "                print(f\"데이터 처리 오류: {e}\")\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dataset = IMDBDataset(train_iter)\n",
    "test_dataset = IMDBDataset(test_iter)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# 모델 정의\n",
    "class CNNTransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(CNNTransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab[\"<pad>\"])\n",
    "        self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
    "\n",
    "        # CNN 인코더\n",
    "        self.cnn_encoder = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=3, padding=1, stride=2)\n",
    "        self.cnn_encoder_residual = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=1, stride=2)\n",
    "\n",
    "        # 트랜스포머 인코더 레이어\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=8, dropout=0.1, activation='relu')\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2, norm=nn.LayerNorm(embedding_dim))\n",
    "\n",
    "        # CNN 디코더\n",
    "        self.cnn_decoder = nn.ConvTranspose1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "        self.cnn_decoder_residual = nn.ConvTranspose1d(embedding_dim, embedding_dim, kernel_size=1, stride=2, output_padding=1)\n",
    "\n",
    "        # 출력 레이어\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        # 임베딩 및 포지셔널 인코딩 추가\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
    "        positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
    "        x = x + self.position_embedding(positions)\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
    "\n",
    "        # CNN 인코더와 잔차 연결\n",
    "        residual = self.cnn_encoder_residual(x)\n",
    "        x = self.cnn_encoder(x)\n",
    "        x = nn.ReLU()(x + residual)\n",
    "\n",
    "        x = x.permute(2, 0, 1)  # [seq_len', batch_size, embedding_dim]\n",
    "\n",
    "        # 패딩 마스크 생성\n",
    "        src_key_padding_mask = (x.abs().sum(dim=2) == 0).transpose(0, 1)\n",
    "\n",
    "        # 트랜스포머 인코더\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        x = x.permute(1, 2, 0)  # [batch_size, embedding_dim, seq_len']\n",
    "\n",
    "        # CNN 디코더와 잔차 연결\n",
    "        residual = self.cnn_decoder_residual(x)\n",
    "        x = self.cnn_decoder(x)\n",
    "        x = nn.ReLU()(x + residual)\n",
    "\n",
    "        # 글로벌 평균 풀링\n",
    "        x = x.mean(dim=2)  # [batch_size, embedding_dim]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)  # [batch_size, num_classes]\n",
    "        return logits\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES).to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"에포크 {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for texts, labels in progress_bar:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"에포크 [{epoch+1}/{NUM_EPOCHS}], 평균 손실: {avg_loss:.4f}\")\n",
    "\n",
    "    # 매 에포크 후 평가\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f\"에포크 {epoch+1} 후 테스트 정확도: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'cnn_transformer_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-transformer-hybrid-model-fa1p7jlT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
