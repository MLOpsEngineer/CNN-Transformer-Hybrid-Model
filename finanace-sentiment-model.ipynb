{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "g1g2WOacWRvVIvv0FhDIPfdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 26467,
          "status": "ok",
          "timestamp": 1727847363104,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "g1g2WOacWRvVIvv0FhDIPfdc",
        "outputId": "7990972c-81ce-445f-ec12-56673c40dbcb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# !pip uninstall torch -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "W9Y0dH7Wuk4B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3609,
          "status": "ok",
          "timestamp": 1728107576222,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "W9Y0dH7Wuk4B",
        "outputId": "e110c770-b398-4e21-f315-5662c4dec6b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Stc7itcyvEt2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 48552,
          "status": "ok",
          "timestamp": 1727847671514,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "Stc7itcyvEt2",
        "outputId": "9fb96c58-989c-4b1b-b702-e67caf7fa09b"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "aTcjH2ydv_oK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 7424,
          "status": "ok",
          "timestamp": 1727847740535,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "aTcjH2ydv_oK",
        "outputId": "6ee09994-24f5-4aec-db75-fa1a03c90b01"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6317818c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#최조코드\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원 (200차원 벡터 사용)\n",
        "NUM_CLASSES = 3  # 클래스 수 (Negative, Neutral, Positive)\n",
        "NUM_EPOCHS = 20  # 학습 에폭 수\n",
        "LEARNING_RATE = 1e-4  # 학습률\n",
        "MAX_VOCAB_SIZE = 20000  # 최대 어휘 사전 크기\n",
        "MAX_SEQ_LEN = 256  # 최대 시퀀스 길이\n",
        "\n",
        "# 디바이스 설정 (GPU 사용 가능 시 GPU 사용)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 타입 선택: 'hybrid', 'cnn', 'transformer'\n",
        "model_type = 'hybrid'  # 현재는 하이브리드 모델 사용\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')  # 금융 문장 데이터셋\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')  # 금융 관련 트윗 데이터셋\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑 (레이블 통일을 위해)\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)  # 레이블 매핑 적용\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})  # 열 이름 변경 (tweet -> sentence)\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합 (두 데이터셋 합치기)\n",
        "combined_data = pd.concat([data1[['sentence', 'label']], data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할 (훈련, 검증, 테스트 세트로 나누기)\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 데이터 전처리 함수 정의\n",
        "def preprocess_text(text):\n",
        "    # URL 제거\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # @멘션 및 해시태그 제거\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    # 특수 문자 및 숫자 제거 (알파벳과 공백만 남김)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    # 소문자로 변환 및 양쪽 공백 제거\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 전처리 적용 (훈련, 검증, 테스트 데이터에 대해)\n",
        "train_data['sentence'] = train_data['sentence'].apply(preprocess_text)\n",
        "val_data['sentence'] = val_data['sentence'].apply(preprocess_text)\n",
        "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')  # 기본 영어 토크나이저 사용\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(str(sentence))  # 각 문장을 토큰화하여 반환\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']  # 패딩 토큰과 미등록 토큰 추가\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])  # 미등록 토큰에 대한 기본 인덱스 설정\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드 (Twitter 데이터로 학습된 임베딩 사용)\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성 (각 단어에 대한 임베딩 벡터 매핑)\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]  # 사전에 있는 단어는 해당 임베딩 사용\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)  # 사전에 없는 단어는 랜덤 초기화\n",
        "\n",
        "# 데이터셋 클래스 정의 (PyTorch Dataset 상속)\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab  # 어휘 사전\n",
        "        self.tokenizer = tokenizer  # 토크나이저\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.data.loc[idx, 'sentence'])  # 문장 추출\n",
        "        label = self.data.loc[idx, 'label']  # 레이블 추출\n",
        "        tokens = self.tokenizer(sentence)  # 문장 토큰화\n",
        "        token_ids = [self.vocab[token] for token in tokens]  # 토큰을 인덱스로 변환\n",
        "        # 시퀀스 길이 조정 (패딩 또는 잘라내기)\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)  # 텐서로 변환\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor  # 텍스트와 레이블 반환\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "# DataLoader를 사용하여 배치 처리\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산 (데이터 불균형 대응을 위해)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)  # 텐서로 변환하여 디바이스에 로드\n",
        "\n",
        "# 모델 정의\n",
        "if model_type == 'hybrid':\n",
        "    # CNN과 트랜스포머를 결합한 하이브리드 모델 정의\n",
        "    class CNNTransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNTransformerModel, self).__init__()\n",
        "            # 임베딩 레이어 (사전 학습된 임베딩 사용)\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            # 위치 임베딩 (포지셔널 인코딩)\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # CNN 인코더 (지역적 특징 추출)\n",
        "            self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "            self.layer_norm_cnn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어 정의\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            # 트랜스포머 인코더를 여러 층 쌓음 (깊은 모델)\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=4, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어 (분류를 위한)\n",
        "            self.dropout = nn.Dropout(0.6)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)  # 단어 임베딩\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)  # 위치 인덱스 생성\n",
        "            x = x + self.position_embedding(positions)  # 위치 임베딩 추가\n",
        "            x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]으로 변환\n",
        "\n",
        "            # CNN 인코더 적용 (지역적 특징 추출)\n",
        "            x = self.cnn(x)\n",
        "            x = x.permute(0, 2, 1)  # 다시 [batch_size, seq_len, embedding_dim]으로 변환\n",
        "            x = self.layer_norm_cnn(x)  # 레이어 정규화\n",
        "            x = nn.ReLU()(x)  # 활성화 함수 적용\n",
        "\n",
        "            # 패딩 마스크 생성 (패딩된 부분을 마스킹)\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더 적용 (전역적 문맥 학습)\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링 (시퀀스 차원 축소)\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)  # 최종 출력\n",
        "            return logits\n",
        "    # 모델 인스턴스 생성 및 디바이스에 로드\n",
        "    model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'cnn':\n",
        "    # CNN 단독 모델 정의\n",
        "    class CNNModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "\n",
        "            # 다양한 커널 크기를 가진 CNN 레이어 사용 (다중 채널)\n",
        "            self.convs = nn.ModuleList([\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=4, padding=2),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "            ])\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(128 * len(self.convs), num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)  # 단어 임베딩\n",
        "            x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "            # 각 CNN 레이어를 통과하여 특징 맵 생성\n",
        "            x = [nn.ReLU()(conv(x)) for conv in self.convs]\n",
        "            # 맥스 풀링으로 시퀀스 차원 축소\n",
        "            x = [nn.functional.max_pool1d(feature_map, kernel_size=feature_map.shape[2]).squeeze(2) for feature_map in x]\n",
        "            x = torch.cat(x, dim=1)  # 특징 맵들을 연결\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)  # 최종 출력\n",
        "            return logits\n",
        "    model = CNNModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'transformer':\n",
        "    # 트랜스포머 단독 모델 정의\n",
        "    class TransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(TransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어 정의\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=8, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            # 트랜스포머 인코더를 여러 층 쌓음\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=4, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)  # 단어 임베딩\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)  # 위치 임베딩 추가\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더 적용\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)  # 최종 출력\n",
        "            return logits\n",
        "    model = TransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)  # 레이블 스무딩 적용\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)  # AdamW 옵티마이저 사용\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping_patience = 3  # 검증 손실이 개선되지 않는 에폭 수\n",
        "best_val_loss = float('inf')  # 최상의 검증 손실 초기값\n",
        "patience_counter = 0  # 인내 횟수 초기화\n",
        "\n",
        "# 학습 루프 시작\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()  # 모델을 훈련 모드로 설정\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()  # 그래디언트 초기화\n",
        "        outputs = model(texts)  # 모델 예측값 계산\n",
        "        loss = criterion(outputs, labels)  # 손실 계산\n",
        "        loss.backward()  # 역전파 수행\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)  # 평균 손실 계산\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 단계\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)  # 예측된 클래스\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader)  # 평균 검증 손실 계산\n",
        "    val_accuracy = correct / total  # 검증 정확도 계산\n",
        "    print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # 조기 종료 조건 확인\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 모델 저장 (최적의 검증 성능)\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")  # 조기 종료 메시지 출력\n",
        "            break\n",
        "\n",
        "# 저장된 모델 로드 (최적의 모델 사용)\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # 예측된 클래스\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total  # 테스트 정확도 계산\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력 (정밀도, 재현율, F1-스코어 등)\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)  # 입력 문장 전처리\n",
        "        tokens = tokenizer(text)  # 토큰화\n",
        "        token_ids = [vocab[token] for token in tokens]  # 토큰 인덱스로 변환\n",
        "        # 시퀀스 길이 조정\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)  # 소프트맥스 적용\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()  # 예측된 클래스\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726aebef",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0QD9kj4uvHJq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5bb70562b224e7fa516bafb3ccd3b35",
            "faaa21f9b821437189d61ea121704a0f",
            "71381184232340d392d877c14832c99d",
            "9f01a8fb90f6465c9cdedf7db1e74f65",
            "e35cc74465934f1fa775564f80839aa0",
            "7a518c54b15847f790e8645d898f664b",
            "ff6746127f954e64aa1aad404934cfc5",
            "9a9553a622e3401493ceb9d2c138b7a5",
            "ae71105026be46618bae750f872d8415",
            "d9c268767b5e47219e9b5156a022be45",
            "55d75ed8d0da423fa00b8ddd3fa620aa",
            "b3bd3812e9384700a207d4648a3c02b5",
            "ea9bdb35ffff4bb29931e13b0e0c3d5d",
            "4e32f1322d2a4f5fadef327389c50aa1",
            "daed1d6e553e4568ba4fa24e7ba767d4",
            "dd683bd52afc424ea6f22df0846367c6",
            "cc83aa2e568d43dbb99aa16386cc63d3",
            "22637d71cc1b4f4c8b24f6b4fbd29a87",
            "e108df3090e34d7c960e2302be11b975",
            "d9fd867d7fae4e848b6a9b96031a95f3",
            "a824637dfe8f4805959ccfbf421afe1d",
            "2007263cfb0b45949077254c07f31f37",
            "7e2dd12ec4e54300a8e1f48fd446195b",
            "06394c31995344e2ab2c9f399581d8bf",
            "78552a306d414dbab3f4baa59f2e878d",
            "9e44750bb0fe43efb8c3db8e058497f5",
            "30f7d6c18a5e42fb8aaff9cc476ff1ea",
            "4f8a41177e0949178b39370afbd174b6",
            "e69668f7613a4237a586ec4a155756fc",
            "02c8134b28e341d783bcc562bbf34af9",
            "624e2a6d98e548a192e18bc1f0cfe2ac",
            "77c4bfb56a0b4874b505ad52b02ed380",
            "84f9e2d01aa441739ef78d94f4f609a3",
            "a87716dda26145af8ce89df273b1b15c",
            "f87893cb66e04846863f27dbbc77b44c",
            "7f6debdfcf344675a86a5c2161c41606",
            "9c9bae9684004b90838ea66baa1f9de8",
            "b8fc59d563614c93b96f76a9d0348b61",
            "3797dd6296074d88bea5e35e7f3ef217",
            "532745be91c640ca96c8f5a10b9131db",
            "f8125a1d8fbd403cbd282759a19480e9",
            "76843a68ec3047d29ff110b2e8306d7a",
            "937b69154b8b46eea079620af2194d0e",
            "565e8fe3a0fc4661a74fb03738b8b2b5",
            "976ab5e857c449109be6676be7ce3690",
            "c45f0097a2614f4eacdc6c3aff67216b",
            "5f61a6269c2d4aaeac53be3f494711bd",
            "ae93ad80c40443e9a2df8c0928bfaa6e",
            "0738e2855dec4981b78d988ca2721848",
            "6262c962f235428592db5fc3b16a12d5",
            "51a5f2056dd649d1acdace91e5c79501",
            "77d3df668dfa40e18c4e902b9d0c1f5d",
            "b5db18b4708741d085f50ba5dce6715b",
            "27b48c6f67524dd7a5f4c671dbb61a6a",
            "87a17a22906847d1921dfbc15a8f09cc"
          ]
        },
        "executionInfo": {
          "elapsed": 223121,
          "status": "ok",
          "timestamp": 1727847985406,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "0QD9kj4uvHJq",
        "outputId": "aac05cf6-678a-4da1-b03c-0f07ed63a6f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5bb70562b224e7fa516bafb3ccd3b35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "financial_phrasebank.py:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3bd3812e9384700a207d4648a3c02b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/8.88k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for financial_phrasebank contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/financial_phrasebank.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e2dd12ec4e54300a8e1f48fd446195b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FinancialPhraseBank-v1.0.zip:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87716dda26145af8ce89df273b1b15c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:20<00:00, 19515.26it/s]\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "976ab5e857c449109be6676be7ce3690",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 57/57 [00:01<00:00, 47.30it/s, loss=1.09]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
            "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.1096\n",
            "Validation Accuracy after Epoch 1: 25.22%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 57/57 [00:00<00:00, 81.35it/s, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 1.1118\n",
            "Validation Accuracy after Epoch 2: 41.59%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 57/57 [00:00<00:00, 83.97it/s, loss=1.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.9779\n",
            "Validation Accuracy after Epoch 3: 60.18%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 57/57 [00:00<00:00, 82.72it/s, loss=0.613]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.8668\n",
            "Validation Accuracy after Epoch 4: 72.57%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 57/57 [00:00<00:00, 82.23it/s, loss=0.687]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7452\n",
            "Validation Accuracy after Epoch 5: 66.37%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 57/57 [00:00<00:00, 83.38it/s, loss=0.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6787\n",
            "Validation Accuracy after Epoch 6: 72.12%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 57/57 [00:00<00:00, 81.72it/s, loss=0.81]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6293\n",
            "Validation Accuracy after Epoch 7: 73.45%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 57/57 [00:00<00:00, 83.04it/s, loss=0.405]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.5889\n",
            "Validation Accuracy after Epoch 8: 74.34%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 57/57 [00:00<00:00, 81.29it/s, loss=0.614]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.5510\n",
            "Validation Accuracy after Epoch 9: 76.11%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 57/57 [00:00<00:00, 82.08it/s, loss=0.423]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.4763\n",
            "Validation Accuracy after Epoch 10: 74.34%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 57/57 [00:00<00:00, 80.71it/s, loss=0.167]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.4260\n",
            "Validation Accuracy after Epoch 11: 83.19%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 57/57 [00:00<00:00, 83.90it/s, loss=0.682]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Average Loss: 0.3038\n",
            "Validation Accuracy after Epoch 12: 83.19%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 57/57 [00:00<00:00, 82.11it/s, loss=0.183]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20], Average Loss: 0.2566\n",
            "Validation Accuracy after Epoch 13: 85.84%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 57/57 [00:00<00:00, 83.65it/s, loss=0.247]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/20], Average Loss: 0.1972\n",
            "Validation Accuracy after Epoch 14: 85.84%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 57/57 [00:00<00:00, 81.61it/s, loss=0.235]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/20], Average Loss: 0.1757\n",
            "Validation Accuracy after Epoch 15: 84.51%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 57/57 [00:00<00:00, 77.92it/s, loss=0.0282]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/20], Average Loss: 0.1205\n",
            "Validation Accuracy after Epoch 16: 83.63%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 57/57 [00:00<00:00, 84.05it/s, loss=0.471]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/20], Average Loss: 0.1613\n",
            "Validation Accuracy after Epoch 17: 87.17%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 57/57 [00:00<00:00, 82.54it/s, loss=0.0642]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/20], Average Loss: 0.1404\n",
            "Validation Accuracy after Epoch 18: 84.51%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 57/57 [00:00<00:00, 82.95it/s, loss=0.0954]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/20], Average Loss: 0.1172\n",
            "Validation Accuracy after Epoch 19: 79.20%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 57/57 [00:00<00:00, 84.37it/s, loss=0.245]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/20], Average Loss: 0.0956\n",
            "Validation Accuracy after Epoch 20: 81.86%\n",
            "\n",
            "Test Accuracy: 79.74%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.77      0.75        31\n",
            "     neutral       0.97      0.80      0.87       139\n",
            "    positive       0.58      0.81      0.68        57\n",
            "\n",
            "    accuracy                           0.80       227\n",
            "   macro avg       0.76      0.79      0.77       227\n",
            "weighted avg       0.84      0.80      0.81       227\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 100  # GloVe 임베딩 차원과 일치시킴\n",
        "NUM_CLASSES = 3  # 클래스 수 (negative, neutral, positive)\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 5e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data = dataset['train'].to_pandas()\n",
        "\n",
        "# 클래스 이름 가져오기\n",
        "label_names = dataset['train'].features['label'].names\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    data, test_size=0.2, stratify=data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(sentence)\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe 임베딩 로드\n",
        "glove = GloVe(name='6B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialPhraseBankDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data.loc[idx, 'sentence']\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        # 시퀀스 길이 조정 및 패딩\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialPhraseBankDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialPhraseBankDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialPhraseBankDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced', classes=np.unique(train_data['label']), y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "        super(CNNTransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "        )\n",
        "        self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "        # CNN 인코더\n",
        "        self.cnn_encoder = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=3, padding=1, stride=2\n",
        "        )\n",
        "        self.cnn_encoder_residual = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=1, stride=2\n",
        "        )\n",
        "\n",
        "        # 트랜스포머 인코더 레이어\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim, nhead=4, dropout=0.1, activation='relu', batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "        )\n",
        "\n",
        "        # CNN 디코더\n",
        "        self.cnn_decoder = nn.ConvTranspose1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=3, padding=1, stride=2, output_padding=1\n",
        "        )\n",
        "        self.cnn_decoder_residual = nn.ConvTranspose1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=1, stride=2, output_padding=1\n",
        "        )\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "        x = self.embedding(x)\n",
        "        positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "        x = x + self.position_embedding(positions)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # CNN 인코더와 잔차 연결\n",
        "        residual = self.cnn_encoder_residual(x)\n",
        "        x = self.cnn_encoder(x)\n",
        "        x = nn.ReLU()(x + residual)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # 패딩 마스크 생성\n",
        "        src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "        # 트랜스포머 인코더\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # CNN 디코더와 잔차 연결\n",
        "        residual = self.cnn_decoder_residual(x)\n",
        "        x = self.cnn_decoder(x)\n",
        "        x = nn.ReLU()(x + residual)\n",
        "        # 글로벌 평균 풀링\n",
        "        x = x.mean(dim=2)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 데이터로 평가\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=label_names))\n",
        "\n",
        "torch.save(model.state_dict(), 'cnn_transformer_model-finance.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YnG8-NT8vcG6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 452,
          "status": "ok",
          "timestamp": 1727848006809,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "YnG8-NT8vcG6",
        "outputId": "b7d92911-0775-44e3-de3e-bcda5083e70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: positive\n",
            "Probabilities: Negative 0.28%, Neutral 0.13%, Positive 99.59%\n"
          ]
        }
      ],
      "source": [
        "# 예측 함수 정의\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = label_names\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaNH8_f_xD8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2995806cb5ba4ac98684a860919e135e",
            "21a0245355e84eecab568643c6e041bb",
            "8796da647740497cac9b1d39980678c9",
            "b451f2579d64425e8e9bffaec7e9345b",
            "a67675bf5cb447b3825d533dbdedae2b",
            "c0cfc0280fb4454d9f9eed38aa3fc8e6",
            "4b6ef5e410bb410e885383589191a9c3",
            "e46526e233774c48b0d49a56c16bd4fe",
            "d1456e8a0ed7460895e71ccbd119355d",
            "29a0c191200b4d7a97c62f808720fa82",
            "094b0c913a11457f8e1c0f1f062bc46e",
            "f3bad0ec0184480d836c7d0e1329fb89",
            "7fd1f92c8f664e19bc6c337d11b08b05",
            "fc43af1b8baa458a9f332af2946cd1ee",
            "4515d86f4bff4a82952c29c8c4d6adf6",
            "ba2670920ab04ad08faf3f4476916464",
            "4ce52d433a8449d5a2eed153950ee03f",
            "b9fb3d15c51f4beda12b0342893ea7e9",
            "231ac5bb056a41dc85909d33d1d06900",
            "6f2b78fed03a4e28a046ae240644f8a8",
            "22bfd8aa379344ca9de6ef6426e0190b",
            "be9f7c71a7234e5cac59ee652db00a6a",
            "e892ee28bf9e479193a0319926d26e28",
            "b1aa9f5c424d400c98e70c913795f8ee",
            "1a92756dc56545c089f9f6fba6d7f427",
            "a7a56553657943f89a25cac8ac0f5bcb",
            "25c6095a95624ab09575f2699913a980",
            "18b1a104270b422b88d53ebab5432a13",
            "6c679d09b92c489bbeaeb0e0ebc178b2",
            "50670e156c344e4696cea655f08a0aa6",
            "88937bf224a44c8ab0e1320178e6763c",
            "63fa70cab3254f20828c08fd1ca8334f",
            "a3fc52d066cb4c66b0baeb67b903453c"
          ]
        },
        "executionInfo": {
          "elapsed": 3442,
          "status": "ok",
          "timestamp": 1727849100657,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "aaNH8_f_xD8b",
        "outputId": "bd9a0364-6a6d-4f8e-a0df-40815b1f64d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2995806cb5ba4ac98684a860919e135e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3bad0ec0184480d836c7d0e1329fb89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e892ee28bf9e479193a0319926d26e28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/38091 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 기존 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "\n",
        "# 새로운 데이터셋 로드\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AE4XbqOf1OQi",
      "metadata": {
        "id": "AE4XbqOf1OQi"
      },
      "outputs": [],
      "source": [
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7hbSpEJg1RYs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1727849203869,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "7hbSpEJg1RYs",
        "outputId": "55672eba-204f-4fbb-d6b3-042715061598"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "sentiment\n",
              "1    17368\n",
              "0    12181\n",
              "2     8542\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data2['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_6oe90b01SSU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1727849327948,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "_6oe90b01SSU",
        "outputId": "e100d631-97d4-40ad-bc3e-1959c13f6d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['tweet', 'sentiment', 'url'], dtype='object')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_jNbSAxL5wUm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 904399,
          "status": "ok",
          "timestamp": 1727851326429,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "_jNbSAxL5wUm",
        "outputId": "72339017-90d8-4ab9-bcf3-0bd686c65973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset shape Counter({2: 14350, 1: 10858, 0: 7076})\n",
            "Validation dataset shape Counter({2: 1794, 1: 1357, 0: 884})\n",
            "Test dataset shape Counter({2: 1794, 1: 1357, 0: 885})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.twitter.27B.zip: 1.52GB [04:45, 5.32MB/s]                            \n",
            "100%|█████████▉| 1193513/1193514 [01:46<00:00, 11197.49it/s]\n",
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.16it/s, loss=0.987]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.0695\n",
            "Validation Accuracy after Epoch 1: 48.43%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.35it/s, loss=0.633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.9161\n",
            "Validation Accuracy after Epoch 2: 64.01%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.64it/s, loss=0.739]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8091\n",
            "Validation Accuracy after Epoch 3: 70.66%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.81it/s, loss=0.767]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7563\n",
            "Validation Accuracy after Epoch 4: 70.33%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.67it/s, loss=0.869]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7138\n",
            "Validation Accuracy after Epoch 5: 73.73%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.75it/s, loss=0.693]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6805\n",
            "Validation Accuracy after Epoch 6: 72.96%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.75it/s, loss=0.572]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6481\n",
            "Validation Accuracy after Epoch 7: 71.50%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.82it/s, loss=0.736]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.6184\n",
            "Validation Accuracy after Epoch 8: 73.43%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.83it/s, loss=0.761]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.5904\n",
            "Validation Accuracy after Epoch 9: 73.58%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.84it/s, loss=0.568]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.5663\n",
            "Validation Accuracy after Epoch 10: 72.86%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.80it/s, loss=0.653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.5429\n",
            "Validation Accuracy after Epoch 11: 72.14%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.84it/s, loss=0.435]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Average Loss: 0.5204\n",
            "Validation Accuracy after Epoch 12: 72.27%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.69it/s, loss=0.555]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20], Average Loss: 0.5003\n",
            "Validation Accuracy after Epoch 13: 73.53%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.54it/s, loss=0.307]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/20], Average Loss: 0.4813\n",
            "Validation Accuracy after Epoch 14: 74.20%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.76it/s, loss=0.483]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/20], Average Loss: 0.4644\n",
            "Validation Accuracy after Epoch 15: 73.09%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.85it/s, loss=0.479]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/20], Average Loss: 0.4563\n",
            "Validation Accuracy after Epoch 16: 73.51%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.77it/s, loss=0.378]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/20], Average Loss: 0.4422\n",
            "Validation Accuracy after Epoch 17: 72.81%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.82it/s, loss=0.445]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/20], Average Loss: 0.4354\n",
            "Validation Accuracy after Epoch 18: 71.80%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.78it/s, loss=0.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/20], Average Loss: 0.4248\n",
            "Validation Accuracy after Epoch 19: 72.71%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 1009/1009 [00:22<00:00, 44.81it/s, loss=0.437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/20], Average Loss: 0.4154\n",
            "Validation Accuracy after Epoch 20: 72.71%\n",
            "\n",
            "Test Accuracy: 73.22%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.64      0.68      0.66       885\n",
            "     Neutral       0.74      0.75      0.75      1357\n",
            "    Positive       0.78      0.74      0.76      1794\n",
            "\n",
            "    accuracy                           0.73      4036\n",
            "   macro avg       0.72      0.72      0.72      4036\n",
            "weighted avg       0.73      0.73      0.73      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Positive\n",
            "Probabilities: Negative 7.53%, Neutral 11.00%, Positive 81.47%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3  # 클래스 수 (Negative, Neutral, Positive)\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합\n",
        "combined_data = pd.concat([data1, data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 클래스 분포 출력\n",
        "print('Train dataset shape %s' % Counter(train_data['label']))\n",
        "print('Validation dataset shape %s' % Counter(val_data['label']))\n",
        "print('Test dataset shape %s' % Counter(test_data['label']))\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(preprocess_text(str(sentence)))\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = preprocess_text(str(self.data.loc[idx, 'sentence']))\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "        super(CNNTransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "        )\n",
        "        self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "        # CNN 인코더\n",
        "        self.cnn_encoder = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=3, padding=1, stride=1\n",
        "        )\n",
        "        self.cnn_encoder_residual = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=1, stride=1\n",
        "        )\n",
        "\n",
        "        # 트랜스포머 인코더 레이어\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "        )\n",
        "\n",
        "        # CNN 디코더\n",
        "        self.cnn_decoder = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=3, padding=1\n",
        "        )\n",
        "        self.cnn_decoder_residual = nn.Conv1d(\n",
        "            embedding_dim, embedding_dim, kernel_size=1\n",
        "        )\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "        x = self.embedding(x)\n",
        "        positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "        x = x + self.position_embedding(positions)\n",
        "        x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "\n",
        "        # CNN 인코더와 잔차 연결\n",
        "        residual = self.cnn_encoder_residual(x)\n",
        "        x = self.cnn_encoder(x)\n",
        "        x = nn.ReLU()(x + residual)\n",
        "\n",
        "        x = x.permute(0, 2, 1)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # 패딩 마스크 생성\n",
        "        src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "        # 트랜스포머 인코더\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "\n",
        "        # CNN 디코더와 잔차 연결\n",
        "        residual = self.cnn_decoder_residual(x)\n",
        "        x = self.cnn_decoder(x)\n",
        "        x = nn.ReLU()(x + residual)\n",
        "\n",
        "        # 글로벌 평균 풀링\n",
        "        x = x.mean(dim=2)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 데이터로 평가\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'cnn_transformer_model_finance.pth')\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5IM64YLt6RtX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 776784,
          "status": "ok",
          "timestamp": 1727852317276,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "5IM64YLt6RtX",
        "outputId": "6b9a2057-2178-47ff-9353-90683e95f9ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:37<00:00, 26.92it/s, loss=0.967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.2577\n",
            "Validation Accuracy after Epoch 1: 39.01%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:37<00:00, 27.27it/s, loss=0.73]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.9581\n",
            "Validation Accuracy after Epoch 2: 61.04%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:37<00:00, 27.26it/s, loss=0.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8118\n",
            "Validation Accuracy after Epoch 3: 72.76%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:37<00:00, 27.03it/s, loss=0.437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7090\n",
            "Validation Accuracy after Epoch 4: 71.47%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.34it/s, loss=0.617]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.6354\n",
            "Validation Accuracy after Epoch 5: 73.11%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.38it/s, loss=0.64]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.5846\n",
            "Validation Accuracy after Epoch 6: 74.80%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.36it/s, loss=0.624]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.5382\n",
            "Validation Accuracy after Epoch 7: 73.46%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.45it/s, loss=0.641]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.5039\n",
            "Validation Accuracy after Epoch 8: 73.41%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.43it/s, loss=0.512]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.4731\n",
            "Validation Accuracy after Epoch 9: 73.18%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.46it/s, loss=0.438]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.4498\n",
            "Validation Accuracy after Epoch 10: 71.55%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 1009/1009 [00:37<00:00, 27.01it/s, loss=0.492]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.4288\n",
            "Validation Accuracy after Epoch 11: 72.91%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 1009/1009 [00:37<00:00, 27.20it/s, loss=0.436]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Average Loss: 0.4137\n",
            "Validation Accuracy after Epoch 12: 72.39%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.38it/s, loss=0.5]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20], Average Loss: 0.4017\n",
            "Validation Accuracy after Epoch 13: 71.50%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.44it/s, loss=0.384]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/20], Average Loss: 0.3973\n",
            "Validation Accuracy after Epoch 14: 71.45%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.45it/s, loss=0.378]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/20], Average Loss: 0.3872\n",
            "Validation Accuracy after Epoch 15: 70.41%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.47it/s, loss=0.386]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/20], Average Loss: 0.3822\n",
            "Validation Accuracy after Epoch 16: 71.82%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.54it/s, loss=0.461]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/20], Average Loss: 0.3757\n",
            "Validation Accuracy after Epoch 17: 71.55%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.53it/s, loss=0.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/20], Average Loss: 0.3741\n",
            "Validation Accuracy after Epoch 18: 71.87%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.51it/s, loss=0.442]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/20], Average Loss: 0.3708\n",
            "Validation Accuracy after Epoch 19: 70.76%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 1009/1009 [00:36<00:00, 27.52it/s, loss=0.518]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/20], Average Loss: 0.3657\n",
            "Validation Accuracy after Epoch 20: 70.46%\n",
            "\n",
            "Test Accuracy: 69.40%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.57      0.66      0.61       885\n",
            "     Neutral       0.74      0.64      0.69      1357\n",
            "    Positive       0.73      0.75      0.74      1794\n",
            "\n",
            "    accuracy                           0.69      4036\n",
            "   macro avg       0.68      0.68      0.68      4036\n",
            "weighted avg       0.70      0.69      0.69      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Positive\n",
            "Probabilities: Negative 4.89%, Neutral 3.73%, Positive 91.38%\n"
          ]
        }
      ],
      "source": [
        "#CNN 레이어 구조 변경 및 하이퍼파라미터 수정 코드\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 5e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "\n",
        "# 모델 정의\n",
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "        super(CNNTransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "        )\n",
        "        self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "        # 멀티채널 CNN 인코더\n",
        "        self.conv1 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=4, padding=2)\n",
        "        self.conv3 = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(embedding_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(embedding_dim)\n",
        "        self.bn3 = nn.BatchNorm1d(embedding_dim)\n",
        "\n",
        "        # 트랜스포머 인코더 레이어\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim, nhead=10, dropout=0.2, activation='relu', batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=2, norm=nn.LayerNorm(embedding_dim)\n",
        "        )\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(embedding_dim * 4, num_classes)  # CNN 3채널 + 트랜스포머 출력\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "        x = self.embedding(x)\n",
        "        positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "        x = x + self.position_embedding(positions)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # 멀티채널 CNN 인코더\n",
        "        x1 = nn.ReLU()(self.bn1(self.conv1(x)))\n",
        "        x2 = nn.ReLU()(self.bn2(self.conv2(x)))\n",
        "        x3 = nn.ReLU()(self.bn3(self.conv3(x)))\n",
        "\n",
        "        # 풀링 및 결합\n",
        "        x1 = nn.functional.max_pool1d(x1, kernel_size=x1.size(2)).squeeze(2)\n",
        "        x2 = nn.functional.max_pool1d(x2, kernel_size=x2.size(2)).squeeze(2)\n",
        "        x3 = nn.functional.max_pool1d(x3, kernel_size=x3.size(2)).squeeze(2)\n",
        "        x_cnn = torch.cat((x1, x2, x3), dim=1)\n",
        "\n",
        "        # 트랜스포머 인코더\n",
        "        x = x.permute(0, 2, 1)\n",
        "        src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # 트랜스포머 출력 풀링\n",
        "        x_transformer = x.mean(dim=1)\n",
        "\n",
        "        # CNN과 트랜스포머 출력 결합\n",
        "        x = torch.cat((x_cnn, x_transformer), dim=1)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 데이터로 평가\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'cnn_transformer_model_finance_v0.2.pth')\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2oJOvf_a--uD",
      "metadata": {
        "id": "2oJOvf_a--uD"
      },
      "source": [
        "성능 향상을 위한 수정\n",
        "\n",
        "1.1 CNN 레이어 구조 변경\n",
        "\n",
        "1.1.1 필터 수 및 커널 크기 조정\n",
        "필터 수 증가: CNN 레이어의 출력 채널 수를 늘려 특징 표현력을 향상시킵니다.\n",
        "예: embedding_dim을 유지하면서, 추가적인 CNN 레이어를 추가하거나, 채널 수를 증가시킵니다.\n",
        "커널 크기 다양화: 다양한 커널 크기를 사용하는 멀티채널 CNN 구조를 도입하여, 다양한 n-그램(n-gram) 특징을 포착합니다.\n",
        "예: 커널 크기 [3, 4, 5]를 사용하는 여러 CNN 레이어를 병렬로 적용하고, 결과를 결합합니다.\n",
        "\n",
        "1.1.2 CNN 레이어 추가\n",
        "CNN 인코더에 추가적인 레이어를 쌓아 깊이를 늘립니다.\n",
        "각 레이어마다 활성화 함수와 정규화 층을 추가하여 학습 안정성을 높입니다.\n",
        "\n",
        "1.2 트랜스포머 모델 고도화\n",
        "\n",
        "1.2.1 레이어 수 및 헤드 수 조정\n",
        "트랜스포머 인코더 레이어 수 증가: num_layers를 1에서 2 또는 3으로 늘려 모델의 표현력을 높입니다.\n",
        "어텐션 헤드 수 조정: nhead를 늘려 모델이 다양한 표현을 학습할 수 있도록 합니다.\n",
        "단, embedding_dim이 nhead로 나누어 떨어져야 합니다.\n",
        "예: embedding_dim=200, nhead=20\n",
        "\n",
        "1.2.2 드롭아웃 비율 조정\n",
        "드롭아웃 비율을 조정하여 과적합을 방지하고 일반화 성능을 향상시킵니다.\n",
        "예: dropout=0.1에서 dropout=0.2로 증가\n",
        "\n",
        "1.3 하이퍼파라미터 튜닝\n",
        "\n",
        "1.3.1 학습률 조정\n",
        "학습률을 약간 높여 학습 속도를 향상시키고, 지역 최솟값에 빠지는 것을 방지합니다.\n",
        "예: LEARNING_RATE = 1e-4에서 LEARNING_RATE = 5e-4로 증가\n",
        "\n",
        "1.3.2 배치 크기 조정\n",
        "배치 크기를 늘려 학습의 안정성을 높입니다.\n",
        "예: BATCH_SIZE = 32에서 BATCH_SIZE = 64로 증가\n",
        "\n",
        "1.4 정규화 및 최적화 기법 적용\n",
        "\n",
        "1.4.1 배치 정규화\n",
        "CNN 레이어나 트랜스포머 레이어 사이에 **배치 정규화(Batch Normalization)**를 적용하여 학습을 안정화시킵니다.\n",
        "\n",
        "1.4.2 옵티마이저 변경\n",
        "AdamW에서 RAdam이나 Lookahead 옵티마이저를 사용하여 학습의 안정성을 높입니다.\n",
        "\n",
        "1.5 임베딩 층 고정 및 미세조정\n",
        "현재 임베딩 층은 학습 가능한 상태입니다.\n",
        "**임베딩 층을 고정(freeze)**하여 학습 파라미터 수를 줄이고, 모델의 수렴을 빠르게 할 수 있습니다.\n",
        "또는, **임베딩 층을 미세조정(fine-tuning)**하여 모델의 표현력을 높일 수 있습니다.\n",
        "\n",
        "1.6 추가적인 데이터 전처리\n",
        "텍스트 정규화를 더 강화하여 노이즈를 줄입니다.\n",
        "예: 표제어 추출(lemmatization), 불용어 제거(stopword removal)\n",
        "데이터 증강을 통해 데이터의 다양성을 높입니다.\n",
        "예: 역번역(Back Translation), 동의어 치환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spyLkLGQBxe2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 224977,
          "status": "ok",
          "timestamp": 1727852967465,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "spyLkLGQBxe2",
        "outputId": "342daf28-76c9-4219-c0d9-1314af7f816a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:20<00:00, 48.22it/s, loss=0.997]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:384: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
            "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.0850\n",
            "Validation Loss after Epoch 1: 0.9682\n",
            "Validation Accuracy after Epoch 1: 59.08%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.12it/s, loss=0.839]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.9152\n",
            "Validation Loss after Epoch 2: 0.8515\n",
            "Validation Accuracy after Epoch 2: 67.78%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:20<00:00, 48.93it/s, loss=0.745]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8163\n",
            "Validation Loss after Epoch 3: 0.8126\n",
            "Validation Accuracy after Epoch 3: 69.67%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:20<00:00, 48.67it/s, loss=0.866]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7654\n",
            "Validation Loss after Epoch 4: 0.7879\n",
            "Validation Accuracy after Epoch 4: 72.47%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:20<00:00, 48.73it/s, loss=0.882]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7238\n",
            "Validation Loss after Epoch 5: 0.8282\n",
            "Validation Accuracy after Epoch 5: 71.08%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.12it/s, loss=0.462]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6884\n",
            "Validation Loss after Epoch 6: 0.7920\n",
            "Validation Accuracy after Epoch 6: 71.70%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.13it/s, loss=0.752]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6595\n",
            "Validation Loss after Epoch 7: 0.7701\n",
            "Validation Accuracy after Epoch 7: 73.56%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.15it/s, loss=0.675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.6315\n",
            "Validation Loss after Epoch 8: 0.8044\n",
            "Validation Accuracy after Epoch 8: 74.18%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.03it/s, loss=0.463]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.6058\n",
            "Validation Loss after Epoch 9: 0.7979\n",
            "Validation Accuracy after Epoch 9: 73.18%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:20<00:00, 49.10it/s, loss=0.682]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.5820\n",
            "Validation Loss after Epoch 10: 0.8357\n",
            "Validation Accuracy after Epoch 10: 74.42%\n",
            "\n",
            "Early stopping triggered.\n",
            "Test Accuracy: 73.04%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.59      0.74      0.66       885\n",
            "     Neutral       0.76      0.73      0.75      1357\n",
            "    Positive       0.80      0.72      0.76      1794\n",
            "\n",
            "    accuracy                           0.73      4036\n",
            "   macro avg       0.72      0.73      0.72      4036\n",
            "weighted avg       0.74      0.73      0.73      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Positive\n",
            "Probabilities: Negative 10.43%, Neutral 7.26%, Positive 82.31%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe, build_vocab_from_iterator  # 수정된 부분\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합\n",
        "combined_data = pd.concat([data1[['sentence', 'label']], data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 전처리 적용\n",
        "train_data['sentence'] = train_data['sentence'].apply(preprocess_text)\n",
        "val_data['sentence'] = val_data['sentence'].apply(preprocess_text)\n",
        "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(str(sentence))\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.data.loc[idx, 'sentence'])\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "class CNNTransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "        super(CNNTransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "        )\n",
        "        self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "        # 단일 CNN 인코더\n",
        "        self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "        self.layer_norm_cnn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        # 트랜스포머 인코더 레이어\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "        )\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size()\n",
        "        x = self.embedding(x)\n",
        "        positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "        x = x + self.position_embedding(positions)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        # CNN 인코더\n",
        "        x = self.cnn(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.layer_norm_cnn(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        # 패딩 마스크 생성\n",
        "        src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "        # 트랜스포머 인코더\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # 글로벌 평균 풀링\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5WvFH-ugQarQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 256449,
          "status": "ok",
          "timestamp": 1728108503405,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "5WvFH-ugQarQ",
        "outputId": "6e3ff09d-04ef-414f-9b9d-5b71dfd032da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:22<00:00, 45.20it/s, loss=0.972]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.0969\n",
            "Validation Loss after Epoch 1: 1.0110\n",
            "Validation Accuracy after Epoch 1: 48.48%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:22<00:00, 45.67it/s, loss=0.937]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.9313\n",
            "Validation Loss after Epoch 2: 0.8735\n",
            "Validation Accuracy after Epoch 2: 60.62%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.09it/s, loss=0.909]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8333\n",
            "Validation Loss after Epoch 3: 0.8148\n",
            "Validation Accuracy after Epoch 3: 68.35%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.22it/s, loss=0.725]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7685\n",
            "Validation Loss after Epoch 4: 0.7945\n",
            "Validation Accuracy after Epoch 4: 71.57%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.41it/s, loss=0.727]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7301\n",
            "Validation Loss after Epoch 5: 0.7904\n",
            "Validation Accuracy after Epoch 5: 71.67%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.28it/s, loss=0.832]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6904\n",
            "Validation Loss after Epoch 6: 0.8062\n",
            "Validation Accuracy after Epoch 6: 73.21%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.37it/s, loss=0.638]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6606\n",
            "Validation Loss after Epoch 7: 0.7906\n",
            "Validation Accuracy after Epoch 7: 70.66%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.30it/s, loss=0.745]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.6315\n",
            "Validation Loss after Epoch 8: 0.7847\n",
            "Validation Accuracy after Epoch 8: 74.47%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.52it/s, loss=0.72]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.6061\n",
            "Validation Loss after Epoch 9: 0.7906\n",
            "Validation Accuracy after Epoch 9: 72.02%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.32it/s, loss=0.651]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.5807\n",
            "Validation Loss after Epoch 10: 0.8173\n",
            "Validation Accuracy after Epoch 10: 72.74%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 1009/1009 [00:21<00:00, 47.58it/s, loss=0.375]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.5572\n",
            "Validation Loss after Epoch 11: 0.8161\n",
            "Validation Accuracy after Epoch 11: 73.98%\n",
            "\n",
            "Early stopping triggered.\n",
            "Test Accuracy: 74.28%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.67      0.64      0.65       885\n",
            "     Neutral       0.74      0.77      0.76      1357\n",
            "    Positive       0.78      0.77      0.78      1794\n",
            "\n",
            "    accuracy                           0.74      4036\n",
            "   macro avg       0.73      0.73      0.73      4036\n",
            "weighted avg       0.74      0.74      0.74      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Positive\n",
            "Probabilities: Negative 16.78%, Neutral 5.53%, Positive 77.70%\n"
          ]
        }
      ],
      "source": [
        "#세가지 모델 테스트 중 hybrid\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 타입 선택: 'hybrid', 'cnn', 'transformer'\n",
        "model_type = 'hybrid'  # 'cnn' 또는 'transformer'로 변경하여 모델 변경\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합\n",
        "combined_data = pd.concat([data1[['sentence', 'label']], data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 전처리 적용\n",
        "train_data['sentence'] = train_data['sentence'].apply(preprocess_text)\n",
        "val_data['sentence'] = val_data['sentence'].apply(preprocess_text)\n",
        "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(str(sentence))\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.data.loc[idx, 'sentence'])\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "if model_type == 'hybrid':\n",
        "    class CNNTransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNTransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # CNN 인코더\n",
        "            self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "            self.layer_norm_cnn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.6)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "            x = x.permute(0, 2, 1)\n",
        "\n",
        "            # CNN 인코더\n",
        "            x = self.cnn(x)\n",
        "            x = x.permute(0, 2, 1)\n",
        "            x = self.layer_norm_cnn(x)\n",
        "            x = nn.ReLU()(x)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'cnn':\n",
        "    class CNNModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "\n",
        "            # 여러 개의 CNN 레이어를 사용하여 다양한 커널 크기 적용\n",
        "            self.convs = nn.ModuleList([\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=4, padding=2),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "            ])\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(128 * len(self.convs), num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "            x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "            x = [nn.ReLU()(conv(x)) for conv in self.convs]\n",
        "            x = [nn.functional.max_pool1d(feature_map, kernel_size=feature_map.shape[2]).squeeze(2) for feature_map in x]\n",
        "            x = torch.cat(x, dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'transformer':\n",
        "    class TransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(TransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=8, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=2, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = TransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Bc9E0fDXRzRI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 140038,
          "status": "ok",
          "timestamp": 1728108643441,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "Bc9E0fDXRzRI",
        "outputId": "31965109-e60c-4950-d790-ab449da583d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:09<00:00, 101.71it/s, loss=0.946]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.0159\n",
            "Validation Loss after Epoch 1: 0.9316\n",
            "Validation Accuracy after Epoch 1: 61.14%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:09<00:00, 102.61it/s, loss=0.859]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.8995\n",
            "Validation Loss after Epoch 2: 0.8675\n",
            "Validation Accuracy after Epoch 2: 66.86%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.65it/s, loss=0.679]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8239\n",
            "Validation Loss after Epoch 3: 0.8217\n",
            "Validation Accuracy after Epoch 3: 69.02%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.76it/s, loss=0.806]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7672\n",
            "Validation Loss after Epoch 4: 0.7944\n",
            "Validation Accuracy after Epoch 4: 70.33%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.75it/s, loss=0.703]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7227\n",
            "Validation Loss after Epoch 5: 0.7834\n",
            "Validation Accuracy after Epoch 5: 72.89%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.34it/s, loss=0.557]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6880\n",
            "Validation Loss after Epoch 6: 0.7730\n",
            "Validation Accuracy after Epoch 6: 72.99%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.18it/s, loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6571\n",
            "Validation Loss after Epoch 7: 0.7632\n",
            "Validation Accuracy after Epoch 7: 73.71%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:09<00:00, 102.82it/s, loss=0.664]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.6293\n",
            "Validation Loss after Epoch 8: 0.7565\n",
            "Validation Accuracy after Epoch 8: 74.40%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.26it/s, loss=0.575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.6056\n",
            "Validation Loss after Epoch 9: 0.7617\n",
            "Validation Accuracy after Epoch 9: 75.04%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.35it/s, loss=0.634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.5851\n",
            "Validation Loss after Epoch 10: 0.7551\n",
            "Validation Accuracy after Epoch 10: 74.32%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.38it/s, loss=0.494]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.5645\n",
            "Validation Loss after Epoch 11: 0.7595\n",
            "Validation Accuracy after Epoch 11: 75.14%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 1009/1009 [00:09<00:00, 103.72it/s, loss=0.647]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Average Loss: 0.5495\n",
            "Validation Loss after Epoch 12: 0.7585\n",
            "Validation Accuracy after Epoch 12: 75.14%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 1009/1009 [00:09<00:00, 102.59it/s, loss=0.575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20], Average Loss: 0.5344\n",
            "Validation Loss after Epoch 13: 0.7609\n",
            "Validation Accuracy after Epoch 13: 74.92%\n",
            "\n",
            "Early stopping triggered.\n",
            "Test Accuracy: 75.30%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.64      0.76      0.69       885\n",
            "     Neutral       0.75      0.80      0.77      1357\n",
            "    Positive       0.84      0.71      0.77      1794\n",
            "\n",
            "    accuracy                           0.75      4036\n",
            "   macro avg       0.74      0.76      0.75      4036\n",
            "weighted avg       0.76      0.75      0.75      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Positive\n",
            "Probabilities: Negative 35.95%, Neutral 7.24%, Positive 56.80%\n"
          ]
        }
      ],
      "source": [
        "#세가지 모델 테스트 중 CNN\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 타입 선택: 'hybrid', 'cnn', 'transformer'\n",
        "model_type = 'cnn'  # 'cnn' 또는 'transformer'로 변경하여 모델 변경\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합\n",
        "combined_data = pd.concat([data1[['sentence', 'label']], data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 전처리 적용\n",
        "train_data['sentence'] = train_data['sentence'].apply(preprocess_text)\n",
        "val_data['sentence'] = val_data['sentence'].apply(preprocess_text)\n",
        "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(str(sentence))\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.data.loc[idx, 'sentence'])\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "if model_type == 'hybrid':\n",
        "    class CNNTransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNTransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # CNN 인코더\n",
        "            self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "            self.layer_norm_cnn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.6)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "            x = x.permute(0, 2, 1)\n",
        "\n",
        "            # CNN 인코더\n",
        "            x = self.cnn(x)\n",
        "            x = x.permute(0, 2, 1)\n",
        "            x = self.layer_norm_cnn(x)\n",
        "            x = nn.ReLU()(x)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'cnn':\n",
        "    class CNNModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "\n",
        "            # 여러 개의 CNN 레이어를 사용하여 다양한 커널 크기 적용\n",
        "            self.convs = nn.ModuleList([\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=4, padding=2),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "            ])\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(128 * len(self.convs), num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "            x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "            x = [nn.ReLU()(conv(x)) for conv in self.convs]\n",
        "            x = [nn.functional.max_pool1d(feature_map, kernel_size=feature_map.shape[2]).squeeze(2) for feature_map in x]\n",
        "            x = torch.cat(x, dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'transformer':\n",
        "    class TransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(TransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=8, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=2, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = TransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Vry0gppzR3fw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 518805,
          "status": "ok",
          "timestamp": 1728109162244,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -540
        },
        "id": "Vry0gppzR3fw",
        "outputId": "eeab168b-b3d9-4b3f-a533-23a19aaa2792"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 1009/1009 [00:41<00:00, 24.49it/s, loss=1.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Average Loss: 1.0701\n",
            "Validation Loss after Epoch 1: 0.9451\n",
            "Validation Accuracy after Epoch 1: 53.48%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.64it/s, loss=0.8]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Average Loss: 0.8941\n",
            "Validation Loss after Epoch 2: 0.8417\n",
            "Validation Accuracy after Epoch 2: 66.39%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 1009/1009 [00:41<00:00, 24.57it/s, loss=0.66]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Average Loss: 0.8108\n",
            "Validation Loss after Epoch 3: 0.7975\n",
            "Validation Accuracy after Epoch 3: 70.04%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.64it/s, loss=0.825]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Average Loss: 0.7591\n",
            "Validation Loss after Epoch 4: 0.7882\n",
            "Validation Accuracy after Epoch 4: 71.90%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.62it/s, loss=0.426]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Average Loss: 0.7218\n",
            "Validation Loss after Epoch 5: 0.8127\n",
            "Validation Accuracy after Epoch 5: 71.95%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 1009/1009 [00:41<00:00, 24.60it/s, loss=0.606]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Average Loss: 0.6901\n",
            "Validation Loss after Epoch 6: 0.7842\n",
            "Validation Accuracy after Epoch 6: 72.89%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 1009/1009 [00:41<00:00, 24.59it/s, loss=0.547]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Average Loss: 0.6605\n",
            "Validation Loss after Epoch 7: 0.7871\n",
            "Validation Accuracy after Epoch 7: 74.80%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 1009/1009 [00:41<00:00, 24.58it/s, loss=0.683]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Average Loss: 0.6318\n",
            "Validation Loss after Epoch 8: 0.7819\n",
            "Validation Accuracy after Epoch 8: 72.29%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.64it/s, loss=0.73]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Average Loss: 0.6059\n",
            "Validation Loss after Epoch 9: 0.7748\n",
            "Validation Accuracy after Epoch 9: 73.36%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.64it/s, loss=0.65]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Average Loss: 0.5838\n",
            "Validation Loss after Epoch 10: 0.8118\n",
            "Validation Accuracy after Epoch 10: 72.52%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.61it/s, loss=0.596]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Average Loss: 0.5580\n",
            "Validation Loss after Epoch 11: 0.8139\n",
            "Validation Accuracy after Epoch 11: 73.78%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 1009/1009 [00:40<00:00, 24.64it/s, loss=0.7]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Average Loss: 0.5356\n",
            "Validation Loss after Epoch 12: 0.8526\n",
            "Validation Accuracy after Epoch 12: 73.38%\n",
            "\n",
            "Early stopping triggered.\n",
            "Test Accuracy: 73.07%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.60      0.73      0.66       885\n",
            "     Neutral       0.73      0.75      0.74      1357\n",
            "    Positive       0.82      0.71      0.76      1794\n",
            "\n",
            "    accuracy                           0.73      4036\n",
            "   macro avg       0.72      0.73      0.72      4036\n",
            "weighted avg       0.74      0.73      0.73      4036\n",
            "\n",
            "\n",
            "Sentence: The company's profits have increased significantly this quarter.\n",
            "Predicted Sentiment: Neutral\n",
            "Probabilities: Negative 33.67%, Neutral 39.89%, Positive 26.44%\n"
          ]
        }
      ],
      "source": [
        "#세가지 모델 테스트 중 Transformer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import GloVe, build_vocab_from_iterator\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 200  # GloVe-Twitter 임베딩 차원\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "MAX_VOCAB_SIZE = 20000\n",
        "MAX_SEQ_LEN = 256\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 모델 타입 선택: 'hybrid', 'cnn', 'transformer'\n",
        "model_type = 'transformer'  # 'cnn' 또는 'transformer'로 변경하여 모델 변경\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset1 = load_dataset('financial_phrasebank', 'sentences_allagree')\n",
        "dataset2 = load_dataset('TimKoornstra/financial-tweets-sentiment')\n",
        "\n",
        "# 데이터프레임으로 변환\n",
        "data1 = dataset1['train'].to_pandas()\n",
        "data2 = dataset2['train'].to_pandas()\n",
        "\n",
        "# dataset2의 레이블 매핑\n",
        "label_mapping2 = {\n",
        "    0: 1,  # Neutral -> Neutral (1)\n",
        "    1: 2,  # Positive -> Positive (2)\n",
        "    2: 0   # Negative -> Negative (0)\n",
        "}\n",
        "\n",
        "data2['label'] = data2['sentiment'].map(label_mapping2)\n",
        "data2 = data2.rename(columns={'tweet': 'sentence'})\n",
        "data2 = data2[['sentence', 'label']]  # 필요한 열만 선택\n",
        "\n",
        "# 데이터 결합\n",
        "combined_data = pd.concat([data1[['sentence', 'label']], data2], ignore_index=True)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, temp_data = train_test_split(\n",
        "    combined_data, test_size=0.2, stratify=combined_data['label'], random_state=42)\n",
        "val_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, stratify=temp_data['label'], random_state=42)\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# 전처리 적용\n",
        "train_data['sentence'] = train_data['sentence'].apply(preprocess_text)\n",
        "val_data['sentence'] = val_data['sentence'].apply(preprocess_text)\n",
        "test_data['sentence'] = test_data['sentence'].apply(preprocess_text)\n",
        "\n",
        "# 어휘 사전 구축\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for sentence in data_iter:\n",
        "        yield tokenizer(str(sentence))\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(train_data['sentence']),\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    specials=['<pad>', '<unk>']\n",
        ")\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# 사전 학습된 GloVe-Twitter 임베딩 로드\n",
        "glove = GloVe(name='twitter.27B', dim=EMBEDDING_DIM)\n",
        "\n",
        "# 임베딩 매트릭스 생성\n",
        "embedding_matrix = torch.zeros(len(vocab), EMBEDDING_DIM)\n",
        "for i, token in enumerate(vocab.get_itos()):\n",
        "    if token in glove.stoi:\n",
        "        embedding_matrix[i] = glove[token]\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.randn(EMBEDDING_DIM)\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class FinancialDataset(Dataset):\n",
        "    def __init__(self, data, vocab, tokenizer):\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.data.loc[idx, 'sentence'])\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        tokens = self.tokenizer(sentence)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "        return text_tensor, label_tensor\n",
        "\n",
        "# 데이터셋 및 데이터 로더 생성\n",
        "train_dataset = FinancialDataset(train_data, vocab, tokenizer)\n",
        "val_dataset = FinancialDataset(val_data, vocab, tokenizer)\n",
        "test_dataset = FinancialDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_data['label']),\n",
        "    y=train_data['label']\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# 모델 정의\n",
        "if model_type == 'hybrid':\n",
        "    class CNNTransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNTransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # CNN 인코더\n",
        "            self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=3, padding=1)\n",
        "            self.layer_norm_cnn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=10, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=1, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.6)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "            x = x.permute(0, 2, 1)\n",
        "\n",
        "            # CNN 인코더\n",
        "            x = self.cnn(x)\n",
        "            x = x.permute(0, 2, 1)\n",
        "            x = self.layer_norm_cnn(x)\n",
        "            x = nn.ReLU()(x)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNTransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'cnn':\n",
        "    class CNNModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(CNNModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "\n",
        "            # 여러 개의 CNN 레이어를 사용하여 다양한 커널 크기 적용\n",
        "            self.convs = nn.ModuleList([\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=4, padding=2),\n",
        "                nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "            ])\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(128 * len(self.convs), num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "            x = x.permute(0, 2, 1)  # [batch_size, embedding_dim, seq_len]\n",
        "            x = [nn.ReLU()(conv(x)) for conv in self.convs]\n",
        "            x = [nn.functional.max_pool1d(feature_map, kernel_size=feature_map.shape[2]).squeeze(2) for feature_map in x]\n",
        "            x = torch.cat(x, dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = CNNModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "elif model_type == 'transformer':\n",
        "    class TransformerModel(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, num_classes, embedding_matrix):\n",
        "            super(TransformerModel, self).__init__()\n",
        "            self.embedding = nn.Embedding.from_pretrained(\n",
        "                embedding_matrix, freeze=False, padding_idx=vocab['<pad>']\n",
        "            )\n",
        "            self.position_embedding = nn.Embedding(MAX_SEQ_LEN, embedding_dim)\n",
        "\n",
        "            # 트랜스포머 인코더 레이어\n",
        "            encoder_layer = nn.TransformerEncoderLayer(\n",
        "                d_model=embedding_dim, nhead=8, dropout=0.1, activation='relu', batch_first=True\n",
        "            )\n",
        "            self.transformer_encoder = nn.TransformerEncoder(\n",
        "                encoder_layer, num_layers=2, norm=nn.LayerNorm(embedding_dim)\n",
        "            )\n",
        "\n",
        "            # 출력 레이어\n",
        "            self.dropout = nn.Dropout(0.5)\n",
        "            self.fc = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            batch_size, seq_len = x.size()\n",
        "            x = self.embedding(x)\n",
        "            positions = torch.arange(0, seq_len).unsqueeze(0).expand(batch_size, seq_len).to(device)\n",
        "            x = x + self.position_embedding(positions)\n",
        "\n",
        "            # 패딩 마스크 생성\n",
        "            src_key_padding_mask = (x.abs().sum(dim=2) == 0)\n",
        "\n",
        "            # 트랜스포머 인코더\n",
        "            x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "            # 글로벌 평균 풀링\n",
        "            x = x.mean(dim=1)\n",
        "            x = self.dropout(x)\n",
        "            logits = self.fc(x)\n",
        "            return logits\n",
        "    model = TransformerModel(len(vocab), EMBEDDING_DIM, NUM_CLASSES, embedding_matrix).to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 조기 종료 설정\n",
        "early_stopping_patience = 3\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    for texts, labels in progress_bar:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # 검증 손실 및 정확도 계산\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_loader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Loss after Epoch {epoch+1}: {val_loss:.4f}\")\n",
        "    print(f\"Validation Accuracy after Epoch {epoch+1}: {val_accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # 조기 종료 체크\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        # 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 저장된 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# 테스트 데이터로 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for texts, labels in test_loader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        outputs = model(texts)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report:\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# 예측 함수 정의 및 테스트\n",
        "def predict(text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text = preprocess_text(text)\n",
        "        tokens = tokenizer(text)\n",
        "        token_ids = [vocab[token] for token in tokens]\n",
        "        if len(token_ids) > MAX_SEQ_LEN:\n",
        "            token_ids = token_ids[:MAX_SEQ_LEN]\n",
        "        else:\n",
        "            token_ids += [vocab['<pad>']] * (MAX_SEQ_LEN - len(token_ids))\n",
        "        text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        outputs = model(text_tensor)\n",
        "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "        class_names = ['Negative', 'Neutral', 'Positive']\n",
        "        return class_names[predicted_class], probabilities.squeeze().cpu().numpy()\n",
        "\n",
        "# 예시 문장 예측\n",
        "sample_text = \"The company's profits have increased significantly this quarter.\"\n",
        "label, probs = predict(sample_text)\n",
        "print(f\"\\nSentence: {sample_text}\")\n",
        "print(f\"Predicted Sentiment: {label}\")\n",
        "print(f\"Probabilities: Negative {probs[0]*100:.2f}%, Neutral {probs[1]*100:.2f}%, Positive {probs[2]*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rrbJ5AhCR7kX",
      "metadata": {
        "id": "rrbJ5AhCR7kX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "finanace-sentiment-model",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c8134b28e341d783bcc562bbf34af9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06394c31995344e2ab2c9f399581d8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8a41177e0949178b39370afbd174b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e69668f7613a4237a586ec4a155756fc",
            "value": "FinancialPhraseBank-v1.0.zip: 100%"
          }
        },
        "0738e2855dec4981b78d988ca2721848": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094b0c913a11457f8e1c0f1f062bc46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18b1a104270b422b88d53ebab5432a13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a92756dc56545c089f9f6fba6d7f427": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50670e156c344e4696cea655f08a0aa6",
            "max": 38091,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88937bf224a44c8ab0e1320178e6763c",
            "value": 38091
          }
        },
        "2007263cfb0b45949077254c07f31f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21a0245355e84eecab568643c6e041bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0cfc0280fb4454d9f9eed38aa3fc8e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4b6ef5e410bb410e885383589191a9c3",
            "value": "README.md: 100%"
          }
        },
        "22637d71cc1b4f4c8b24f6b4fbd29a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22bfd8aa379344ca9de6ef6426e0190b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231ac5bb056a41dc85909d33d1d06900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25c6095a95624ab09575f2699913a980": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b48c6f67524dd7a5f4c671dbb61a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2995806cb5ba4ac98684a860919e135e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21a0245355e84eecab568643c6e041bb",
              "IPY_MODEL_8796da647740497cac9b1d39980678c9",
              "IPY_MODEL_b451f2579d64425e8e9bffaec7e9345b"
            ],
            "layout": "IPY_MODEL_a67675bf5cb447b3825d533dbdedae2b"
          }
        },
        "29a0c191200b4d7a97c62f808720fa82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f7d6c18a5e42fb8aaff9cc476ff1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3797dd6296074d88bea5e35e7f3ef217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4515d86f4bff4a82952c29c8c4d6adf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bfd8aa379344ca9de6ef6426e0190b",
            "placeholder": "​",
            "style": "IPY_MODEL_be9f7c71a7234e5cac59ee652db00a6a",
            "value": " 2.65M/2.65M [00:00&lt;00:00, 6.86MB/s]"
          }
        },
        "4b6ef5e410bb410e885383589191a9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce52d433a8449d5a2eed153950ee03f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e32f1322d2a4f5fadef327389c50aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e108df3090e34d7c960e2302be11b975",
            "max": 8878,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9fd867d7fae4e848b6a9b96031a95f3",
            "value": 8878
          }
        },
        "4f8a41177e0949178b39370afbd174b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50670e156c344e4696cea655f08a0aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a5f2056dd649d1acdace91e5c79501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532745be91c640ca96c8f5a10b9131db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d75ed8d0da423fa00b8ddd3fa620aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565e8fe3a0fc4661a74fb03738b8b2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f61a6269c2d4aaeac53be3f494711bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d3df668dfa40e18c4e902b9d0c1f5d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5db18b4708741d085f50ba5dce6715b",
            "value": 0
          }
        },
        "624e2a6d98e548a192e18bc1f0cfe2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6262c962f235428592db5fc3b16a12d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fa70cab3254f20828c08fd1ca8334f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c679d09b92c489bbeaeb0e0ebc178b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f2b78fed03a4e28a046ae240644f8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71381184232340d392d877c14832c99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9553a622e3401493ceb9d2c138b7a5",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae71105026be46618bae750f872d8415",
            "value": 6036
          }
        },
        "76843a68ec3047d29ff110b2e8306d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77c4bfb56a0b4874b505ad52b02ed380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d3df668dfa40e18c4e902b9d0c1f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "78552a306d414dbab3f4baa59f2e878d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c8134b28e341d783bcc562bbf34af9",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624e2a6d98e548a192e18bc1f0cfe2ac",
            "value": 681890
          }
        },
        "7a518c54b15847f790e8645d898f664b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2dd12ec4e54300a8e1f48fd446195b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06394c31995344e2ab2c9f399581d8bf",
              "IPY_MODEL_78552a306d414dbab3f4baa59f2e878d",
              "IPY_MODEL_9e44750bb0fe43efb8c3db8e058497f5"
            ],
            "layout": "IPY_MODEL_30f7d6c18a5e42fb8aaff9cc476ff1ea"
          }
        },
        "7f6debdfcf344675a86a5c2161c41606": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8125a1d8fbd403cbd282759a19480e9",
            "max": 2264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76843a68ec3047d29ff110b2e8306d7a",
            "value": 2264
          }
        },
        "7fd1f92c8f664e19bc6c337d11b08b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce52d433a8449d5a2eed153950ee03f",
            "placeholder": "​",
            "style": "IPY_MODEL_b9fb3d15c51f4beda12b0342893ea7e9",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "84f9e2d01aa441739ef78d94f4f609a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8796da647740497cac9b1d39980678c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46526e233774c48b0d49a56c16bd4fe",
            "max": 4209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1456e8a0ed7460895e71ccbd119355d",
            "value": 4209
          }
        },
        "87a17a22906847d1921dfbc15a8f09cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88937bf224a44c8ab0e1320178e6763c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "937b69154b8b46eea079620af2194d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976ab5e857c449109be6676be7ce3690": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c45f0097a2614f4eacdc6c3aff67216b",
              "IPY_MODEL_5f61a6269c2d4aaeac53be3f494711bd",
              "IPY_MODEL_ae93ad80c40443e9a2df8c0928bfaa6e"
            ],
            "layout": "IPY_MODEL_0738e2855dec4981b78d988ca2721848"
          }
        },
        "9a9553a622e3401493ceb9d2c138b7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9bae9684004b90838ea66baa1f9de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_937b69154b8b46eea079620af2194d0e",
            "placeholder": "​",
            "style": "IPY_MODEL_565e8fe3a0fc4661a74fb03738b8b2b5",
            "value": " 2264/2264 [00:00&lt;00:00, 28160.88 examples/s]"
          }
        },
        "9e44750bb0fe43efb8c3db8e058497f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c4bfb56a0b4874b505ad52b02ed380",
            "placeholder": "​",
            "style": "IPY_MODEL_84f9e2d01aa441739ef78d94f4f609a3",
            "value": " 682k/682k [00:00&lt;00:00, 5.58MB/s]"
          }
        },
        "9f01a8fb90f6465c9cdedf7db1e74f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c268767b5e47219e9b5156a022be45",
            "placeholder": "​",
            "style": "IPY_MODEL_55d75ed8d0da423fa00b8ddd3fa620aa",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 389kB/s]"
          }
        },
        "a3fc52d066cb4c66b0baeb67b903453c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67675bf5cb447b3825d533dbdedae2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a56553657943f89a25cac8ac0f5bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fa70cab3254f20828c08fd1ca8334f",
            "placeholder": "​",
            "style": "IPY_MODEL_a3fc52d066cb4c66b0baeb67b903453c",
            "value": " 38091/38091 [00:00&lt;00:00, 696405.77 examples/s]"
          }
        },
        "a824637dfe8f4805959ccfbf421afe1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a87716dda26145af8ce89df273b1b15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f87893cb66e04846863f27dbbc77b44c",
              "IPY_MODEL_7f6debdfcf344675a86a5c2161c41606",
              "IPY_MODEL_9c9bae9684004b90838ea66baa1f9de8"
            ],
            "layout": "IPY_MODEL_b8fc59d563614c93b96f76a9d0348b61"
          }
        },
        "ae71105026be46618bae750f872d8415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae93ad80c40443e9a2df8c0928bfaa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b48c6f67524dd7a5f4c671dbb61a6a",
            "placeholder": "​",
            "style": "IPY_MODEL_87a17a22906847d1921dfbc15a8f09cc",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "b1aa9f5c424d400c98e70c913795f8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b1a104270b422b88d53ebab5432a13",
            "placeholder": "​",
            "style": "IPY_MODEL_6c679d09b92c489bbeaeb0e0ebc178b2",
            "value": "Generating train split: 100%"
          }
        },
        "b3bd3812e9384700a207d4648a3c02b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea9bdb35ffff4bb29931e13b0e0c3d5d",
              "IPY_MODEL_4e32f1322d2a4f5fadef327389c50aa1",
              "IPY_MODEL_daed1d6e553e4568ba4fa24e7ba767d4"
            ],
            "layout": "IPY_MODEL_dd683bd52afc424ea6f22df0846367c6"
          }
        },
        "b451f2579d64425e8e9bffaec7e9345b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a0c191200b4d7a97c62f808720fa82",
            "placeholder": "​",
            "style": "IPY_MODEL_094b0c913a11457f8e1c0f1f062bc46e",
            "value": " 4.21k/4.21k [00:00&lt;00:00, 228kB/s]"
          }
        },
        "b5db18b4708741d085f50ba5dce6715b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8fc59d563614c93b96f76a9d0348b61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fb3d15c51f4beda12b0342893ea7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba2670920ab04ad08faf3f4476916464": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9f7c71a7234e5cac59ee652db00a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0cfc0280fb4454d9f9eed38aa3fc8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45f0097a2614f4eacdc6c3aff67216b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6262c962f235428592db5fc3b16a12d5",
            "placeholder": "​",
            "style": "IPY_MODEL_51a5f2056dd649d1acdace91e5c79501",
            "value": ""
          }
        },
        "c5bb70562b224e7fa516bafb3ccd3b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faaa21f9b821437189d61ea121704a0f",
              "IPY_MODEL_71381184232340d392d877c14832c99d",
              "IPY_MODEL_9f01a8fb90f6465c9cdedf7db1e74f65"
            ],
            "layout": "IPY_MODEL_e35cc74465934f1fa775564f80839aa0"
          }
        },
        "cc83aa2e568d43dbb99aa16386cc63d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1456e8a0ed7460895e71ccbd119355d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9c268767b5e47219e9b5156a022be45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fd867d7fae4e848b6a9b96031a95f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daed1d6e553e4568ba4fa24e7ba767d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a824637dfe8f4805959ccfbf421afe1d",
            "placeholder": "​",
            "style": "IPY_MODEL_2007263cfb0b45949077254c07f31f37",
            "value": " 8.88k/8.88k [00:00&lt;00:00, 655kB/s]"
          }
        },
        "dd683bd52afc424ea6f22df0846367c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e108df3090e34d7c960e2302be11b975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e35cc74465934f1fa775564f80839aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46526e233774c48b0d49a56c16bd4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69668f7613a4237a586ec4a155756fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e892ee28bf9e479193a0319926d26e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1aa9f5c424d400c98e70c913795f8ee",
              "IPY_MODEL_1a92756dc56545c089f9f6fba6d7f427",
              "IPY_MODEL_a7a56553657943f89a25cac8ac0f5bcb"
            ],
            "layout": "IPY_MODEL_25c6095a95624ab09575f2699913a980"
          }
        },
        "ea9bdb35ffff4bb29931e13b0e0c3d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc83aa2e568d43dbb99aa16386cc63d3",
            "placeholder": "​",
            "style": "IPY_MODEL_22637d71cc1b4f4c8b24f6b4fbd29a87",
            "value": "README.md: 100%"
          }
        },
        "f3bad0ec0184480d836c7d0e1329fb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fd1f92c8f664e19bc6c337d11b08b05",
              "IPY_MODEL_fc43af1b8baa458a9f332af2946cd1ee",
              "IPY_MODEL_4515d86f4bff4a82952c29c8c4d6adf6"
            ],
            "layout": "IPY_MODEL_ba2670920ab04ad08faf3f4476916464"
          }
        },
        "f8125a1d8fbd403cbd282759a19480e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87893cb66e04846863f27dbbc77b44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3797dd6296074d88bea5e35e7f3ef217",
            "placeholder": "​",
            "style": "IPY_MODEL_532745be91c640ca96c8f5a10b9131db",
            "value": "Generating train split: 100%"
          }
        },
        "faaa21f9b821437189d61ea121704a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a518c54b15847f790e8645d898f664b",
            "placeholder": "​",
            "style": "IPY_MODEL_ff6746127f954e64aa1aad404934cfc5",
            "value": "financial_phrasebank.py: 100%"
          }
        },
        "fc43af1b8baa458a9f332af2946cd1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_231ac5bb056a41dc85909d33d1d06900",
            "max": 2648082,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f2b78fed03a4e28a046ae240644f8a8",
            "value": 2648082
          }
        },
        "ff6746127f954e64aa1aad404934cfc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
